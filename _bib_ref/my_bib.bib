@online{chen2022over,
  title={Over-the-Air Computation for Distributed Systems: Something Old and Something New},
  author={Chen, Zheng and Larsson, Erik G and Fischione, Carlo and Johansson, Mikael and Malitsky, Yura},
  eprint={2211.00767},
  eprinttype = {arxiv},
  year={2022}
}

@online{chen2022over-the-air,
  title={Over-the-air computation with multiple receivers: A space-time approach},
  author={Chen, Zheng and Malitsky, Yura},
  eprint={2208.11751},
  eprinttype = {arxiv},
  year={2022}
}


@online{alacaoglu2022beyond,
  title={Beyond the Golden Ratio for Variational Inequality Algorithms},
  author={Alacaoglu, Ahmet and B{\"o}hm, Axel and Malitsky, Yura},
  eprint={2212.13955},
  eprinttype = {arxiv},
  year={2022}
}


@article{aragon2021distributed,
  title={Distributed forward-backward methods for ring networks},
  author={Arag{\'o}n-Artacho, Francisco J and Malitsky, Yura and Tam, Matthew K and Torregrosa-Bel{\'e}n, David},
journal={Computational optimization and applications},
eprint={2112.00274},
  eprinttype = {arxiv},
  year=2022,
  doi={10.1007/s10589-022-00400-z}
}

@InProceedings{vladarean2021,
  title={A first-order primal-dual method with adaptivity to local smoothness},
  author={ Vladarean, Maria-Luiza and  Malitsky, Yura and Cevher, Volkan},
  booktitle = {NeurIPS},
   volume = 34,
   pages = {6171--6182},
  year=2021,
  url={https://papers.nips.cc/paper/2021/hash/310b60949d2b6096903d7e8a539b20f5-Abstract.html},
  eprint={2110.15148},
  eprinttype={arxiv}
}


@article{malitsky2021resolvent,
  title={Resolvent Splitting for Sums of Monotone Operators with Minimal Lifting},
  author={Malitsky, Yura and Tam, Matthew K},
  journal={Mathematical Programming},
  eprint={2108.02897},
  eprinttype = {arxiv},
  year=2022,
  doi={10.1007/s10107-022-01906-4}
}

@inproceedings{alacaoglu2022stochastic,
  title={Stochastic variance reduction for variational inequality methods},
  author={Alacaoglu, Ahmet and Malitsky, Yura},
  booktitle = 	 {Proceedings of Thirty Fifth Conference on Learning Theory},
  pages={778--816},
  year=2022,
  organization={PMLR},
    volume = 	 178,
      url = 	 {https://proceedings.mlr.press/v178/alacaoglu22a.html},
  eprint={2102.08352},
  eprinttype={arxiv},
}


@article{forrefbackvr2021,
title={Forward-reflected-backward method with variance reduction},
author={Alacaoglu, Ahmet and Malitsky, Yura and Cevher, Volkan},
journal={Computational optimization and applications},
volume=80,
  number=2,
  pages={321--346},
  year=2021,
doi={10.1007/s10589-021-00305-3}
}


@InProceedings{alacaoglu2020convergence,
  title={Convergence of adaptive algorithms for weakly convex constrained optimization},
  author={Alacaoglu, Ahmet and Malitsky, Yura and Cevher, Volkan},
  year={2021},
  booktitle = {NeurIPS},
  eprint={2006.06650},
  eprinttype = {arxiv}
}





@InProceedings{Ahmet2020adam_type,
title = {A new regret analysis for {A}dam-type algorithms},
author = {Alacaoglu, Ahmet and Malitsky, Yura and Mertikopoulos,
Panayotis and Cevher, Volkan},
booktitle = {International Conference on Machine Learning},
year = 2020,
url = {http://proceedings.mlr.press/v119/alacaoglu20b.html},
eprint={2003.09729},
eprinttype = {arxiv}
}


@InProceedings{Malitsky2019_descent,
  title = {Adaptive Gradient Descent without Descent},
  author = {Malitsky, Yura and Mishchenko, Konstantin},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 2020,
  url = {http://proceedings.mlr.press/v119/malitsky20a.html},
  eprint={1910.09529},
  eprinttype = {arxiv}
}

@article{Malitsky2019,
author={Malitsky, Yura},
title={Golden ratio algorithms for variational inequalities},
journal={Mathematical Programming},
pages={383--410},
year=2020,
volume=184,
publisher={Springer},
doi="10.1007/s10107-019-01416-w",
eprint={1803.08832},
eprinttype = {arxiv},
}

@article{csetnek2019shadow,
  title={Shadow {Douglas}-{Rachford} splitting for monotone inclusions},
  author={Csetnek, Ern{\"o} Robert and Malitsky, Yura and Tam, Matthew K},
  journal={Applied Mathematics \& Optimization},
  volume=80,
  number=3,
  pages={665--678},
  year=2019,
  publisher={Springer},
  doi={10.1007/s00245-019-09597-8},
  eprint={1903.03393},
  eprinttype={arxiv},
}


@inproceedings{ochs2019model,
  title={Model Function Based Conditional Gradient Method with {{A}rmijo}-like Line Search},
  author={Malitsky, Yura and Ochs, Peter},
  booktitle={International Conference on Machine Learning},
  pages={4891--4900},
  year=2019,
  url = {http://proceedings.mlr.press/v97/ochs19a/ochs19a.pdf},
  eprint={1901.08087},
  eprinttype = {arxiv},
}



@inproceedings{mishchenko2020revisiting,
  title={Revisiting stochastic extragradient},
  author={Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year=2020,
  url = {http://proceedings.mlr.press/v108/mishchenko20a.html},
  eprint={1905.11373},
  eprinttype = {arxiv},
}


@article{malitsky2020forward,
  title={A forward-backward splitting method for monotone inclusions without cocoercivity},
  author={Malitsky, Yura and Tam, Matthew K},
  journal={SIAM Journal on Optimization},
  volume=30,
  number=2,
  pages={1451--1472},
  year=2020,
  publisher={SIAM},
  doi = {10.1137/18M1207260},
  eprint={1808.04162},
  eprinttype = {arxiv}
}

@article{malitsky2018first,
  title={A first-order primal-dual algorithm with linesearch},
  author={Malitsky, Yura and Pock, Thomas},
  journal={SIAM Journal on Optimization},
  volume=28,
  number=1,
  pages={411--432},
  year=2018,
  doi={10.1137/16M1092015},
  eprint={1608.08883},
  eprinttype = {arxiv}
}



@incollection{luke2018block,
  title={Block-Coordinate Primal-Dual Method for Nonsmooth Minimization over Linear Constraints},
  author={Luke, D Russell and Malitsky, Yura},
  booktitle={Large-Scale and Distributed Optimization},
  pages={121--147},
  year=2018,
  publisher={Springer, Cham},
  doi={10.1007/978-3-319-97478-1_6},
  eprint={1801.04782},
  eprinttype = {arxiv}
}


@article{malitsky2018proximal,
  title={Proximal extrapolated gradient methods for variational inequalities},
  author={Malitsky, Yura},
  journal={Optimization Methods and Software},
  volume=33,
  number=1,
  pages={140--164},
  year=2018,
  publisher={Taylor \& Francis},
  doi={10.1080/10556788.2017.1300899},
  eprint={ 1601.04001},
  eprinttype = {arxiv}
}

@online{malitsky2017primal,
  title={The primal-dual hybrid gradient method reduces to a primal method for linearly constrained optimization problems},
  author={Malitsky, Yura},
    eprint={1706.02602},
  eprinttype = {arxiv},
  year=2017
}


@article{malitsky2015hybrid,
  title={A hybrid method without extrapolation step for solving variational inequality problems},
  author={Malitsky, Yura V and Semenov, VV},
  journal={Journal of Global Optimization},
  volume=61,
  number=1,
  pages={193--202},
  year=2015,
  publisher={Springer US},
  doi = {10.1007/s10898-014-0150-x},
  eprint={1501.07298},
  eprinttype = {arxiv}
}

@article{malitsky2015projected,
  title={Projected reflected gradient methods for monotone variational inequalities},
  author={Malitsky, Yura},
  journal={SIAM Journal on Optimization},
  volume=25,
  number=1,
  pages={502--520},
  year=2015,
  publisher={SIAM},
  doi="10.1137/14097238X",
  eprint={1502.04968},
  eprinttype = {arxiv},
  abstract = {SIAM Student Paper Award, 2015}
}



@article{malitsky2014extragradient,
  title={An extragradient algorithm for monotone variational inequalities},
  author={Malitsky, Yura V and Semenov, VV},
  journal={Cybernetics and Systems Analysis},
  volume=50,
  number=2,
  pages={271--277},
  year=2014,
  publisher={Springer US},
  doi={10.1007/s10559-014-9614-8}
}
