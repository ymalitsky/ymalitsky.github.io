@online{malitsky23adaptive,
  title={Adaptive proximal gradient method for convex optimization},
  author={Malitsky, Yura  and  Mishchenko, Konstantin},
  eprint={2308.02261},
  eprinttype = {arxiv},
  year=2023,
}

@online{malitsky2023first,
  title={A First-Order Algorithm for Decentralised Min-Max Problems},
  author={Malitsky, Yura and Tam, Matthew K},
  eprint={2308.11876},
  eprinttype={arXiv},
  year=2023,
}



@article{chen2022over,
  title={Over-the-Air Computation for Distributed Systems: Something Old and Something New},
  author={Chen, Zheng and Larsson, Erik G and Fischione, Carlo and Johansson, Mikael and Malitsky, Yura},
  journal={IEEE Network},
  year=2023,
  publisher={IEEE},
  eprint={2211.00767},
  eprinttype = {arxiv},
  doi={10.1109/MNET.126.2200205}
}


@article{ChenZheng23,
  author={Chen, Zheng and Malitsky, Yura},
  journal={IEEE Wireless Communications Letters}, 
  title={Over-the-Air Computation With Multiple Receivers: A Space-Time Approach}, 
  year=2023,
  volume=12,
  number=8,
  pages={1399-1403},
  doi={10.1109/LWC.2023.3275760}}




@article{alacaoglu2023beyond,
  author       = {Ahmet Alacaoglu and
                  Axel B{\"{o}}hm and
                  Yura Malitsky},
  title        = {Beyond the golden ratio for variational inequality algorithms},
  journal      = {J. Mach. Learn. Res.},
  volume       = 24,
  pages        = {1--33},
  year         = 2023,
  url          = {http://jmlr.org/papers/v24/22-1488.html},
  eprint={2212.13955},
  eprinttype = {arxiv}
}



@article{aragon2021distributed,
  title={Distributed forward-backward methods for ring networks},
  author={Arag{\'o}n-Artacho, Francisco J and Malitsky, Yura and Tam, Matthew K and Torregrosa-Bel{\'e}n, David},
journal={Computational optimization and applications},
eprint={2112.00274},
  eprinttype = {arxiv},
  year=2022,
  doi={10.1007/s10589-022-00400-z}
}

@InProceedings{vladarean2021,
  title={A first-order primal-dual method with adaptivity to local smoothness},
  author={ Vladarean, Maria-Luiza and  Malitsky, Yura and Cevher, Volkan},
  booktitle = {NeurIPS},
   volume = 34,
   pages = {6171--6182},
  year=2021,
  url={https://papers.nips.cc/paper/2021/hash/310b60949d2b6096903d7e8a539b20f5-Abstract.html},
  eprint={2110.15148},
  eprinttype={arxiv}
}


@article{malitsky2021resolvent,
  author       = {Yura Malitsky and
                  Matthew K. Tam},
  title        = {Resolvent splitting for sums of monotone operators with minimal lifting},
  journal      = {Math. Program.},
  volume       = 201,
  number       = 1,
  pages        = {231--262},
  year         = 2023,
  doi          = {10.1007/s10107-022-01906-4},
  eprint={2108.02897},
  eprinttype = {arxiv},
}



@inproceedings{alacaoglu2022stochastic,
  title={Stochastic variance reduction for variational inequality methods},
  author={Alacaoglu, Ahmet and Malitsky, Yura},
  booktitle = 	 {Proceedings of Thirty Fifth Conference on Learning Theory},
  pages={778--816},
  year=2022,
  organization={PMLR},
    volume = 	 178,
      url = 	 {https://proceedings.mlr.press/v178/alacaoglu22a.html},
  eprint={2102.08352},
  eprinttype={arxiv},
}


@article{forrefbackvr2021,
title={Forward-reflected-backward method with variance reduction},
author={Alacaoglu, Ahmet and Malitsky, Yura and Cevher, Volkan},
journal={Computational optimization and applications},
volume=80,
  number=2,
  pages={321--346},
  year=2021,
doi={10.1007/s10589-021-00305-3}
}


@InProceedings{alacaoglu2020convergence,
  title={Convergence of adaptive algorithms for weakly convex constrained optimization},
  author={Alacaoglu, Ahmet and Malitsky, Yura and Cevher, Volkan},
   volume = 34,
  year=2021,
  booktitle = {NeurIPS},
   pages = {14214--14225},
  url={https://papers.nips.cc/paper/2021/hash/76c073d8a82d9ddaf993300be03ac70f-Abstract.html},
  eprint={2006.06650},
  eprinttype = {arxiv}
}





@inproceedings{DBLP:conf/icml/AlacaogluMMC20,
  author       = {Ahmet Alacaoglu and
                  Yura Malitsky and
                  Panayotis Mertikopoulos and
                  Volkan Cevher},
  title        = {A new regret analysis for Adam-type algorithms},
  booktitle    = {Proceedings of the 37th International Conference on Machine Learning},
  volume       = 119,
  pages        = {202--210},
  publisher    = {{PMLR}},
  year         = 2020,
  url          = {http://proceedings.mlr.press/v119/alacaoglu20b.html},
  eprint={2003.09729},
 eprinttype = {arxiv}
}




@inproceedings{malitsky2019_descent,
 author = {Malitsky, Yura and Mishchenko, Konstantin},
 title = {Adaptive gradient descent without descent},
 booktitle = {Proceedings of the 37th International Conference on Machine Learning},
 volume = 119,
 pages = {6702----6712},
 publisher = {{PMLR}},
 year = 2020,
 url = {http://proceedings.mlr.press/v119/malitsky20a.html},
 eprint = {1910.09529},
 eprinttype = {arxiv},
}


@article{Malitsky2019,
author={Malitsky, Yura},
title={Golden ratio algorithms for variational inequalities},
journal={Mathematical Programming},
pages={383--410},
year=2020,
volume=184,
publisher={Springer},
doi="10.1007/s10107-019-01416-w",
eprint={1803.08832},
eprinttype = {arxiv},
}

@article{csetnek2019shadow,
  title={Shadow {Douglas}-{Rachford} splitting for monotone inclusions},
  author={Csetnek, Ern{\"o} Robert and Malitsky, Yura and Tam, Matthew K},
  journal={Applied Mathematics \& Optimization},
  volume=80,
  number=3,
  pages={665--678},
  year=2019,
  publisher={Springer},
  doi={10.1007/s00245-019-09597-8},
  eprint={1903.03393},
  eprinttype={arxiv},
}


@inproceedings{ochs2019model,
  title={Model Function Based Conditional Gradient Method with {{A}rmijo}-like Line Search},
  author={Malitsky, Yura and Ochs, Peter},
  booktitle={Proceedings of the 36th International Conference on Machine Learning},
  pages={4891--4900},
  year=2019,
  url = {http://proceedings.mlr.press/v97/ochs19a/ochs19a.pdf},
  eprint={1901.08087},
  eprinttype = {arxiv},
}



@inproceedings{mishchenko2020revisiting,
  title={Revisiting stochastic extragradient},
  author={Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year=2020,
  url = {http://proceedings.mlr.press/v108/mishchenko20a.html},
  eprint={1905.11373},
  eprinttype = {arxiv},
}


@article{malitsky2020forward,
  title={A forward-backward splitting method for monotone inclusions without cocoercivity},
  author={Malitsky, Yura and Tam, Matthew K},
  journal={SIAM Journal on Optimization},
  volume=30,
  number=2,
  pages={1451--1472},
  year=2020,
  publisher={SIAM},
  doi = {10.1137/18M1207260},
  eprint={1808.04162},
  eprinttype = {arxiv}
}

@article{malitsky2018first,
  title={A first-order primal-dual algorithm with linesearch},
  author={Malitsky, Yura and Pock, Thomas},
  journal={SIAM Journal on Optimization},
  volume=28,
  number=1,
  pages={411--432},
  year=2018,
  doi={10.1137/16M1092015},
  eprint={1608.08883},
  eprinttype = {arxiv}
}



@incollection{luke2018block,
  title={Block-Coordinate Primal-Dual Method for Nonsmooth Minimization over Linear Constraints},
  author={Luke, D Russell and Malitsky, Yura},
  booktitle={Large-Scale and Distributed Optimization},
  pages={121--147},
  year=2018,
  publisher={Springer, Cham},
  doi={10.1007/978-3-319-97478-1_6},
  eprint={1801.04782},
  eprinttype = {arxiv}
}


@article{malitsky2018proximal,
  title={Proximal extrapolated gradient methods for variational inequalities},
  author={Malitsky, Yura},
  journal={Optimization Methods and Software},
  volume=33,
  number=1,
  pages={140--164},
  year=2018,
  publisher={Taylor \& Francis},
  doi={10.1080/10556788.2017.1300899},
  eprint={ 1601.04001},
  eprinttype = {arxiv}
}

@online{malitsky2017primal,
  title={The primal-dual hybrid gradient method reduces to a primal method for linearly constrained optimization problems},
  author={Malitsky, Yura},
    eprint={1706.02602},
  eprinttype = {arxiv},
  year=2017
}


@article{malitsky2015hybrid,
  title={A hybrid method without extrapolation step for solving variational inequality problems},
  author={Malitsky, Yura V and Semenov, VV},
  journal={Journal of Global Optimization},
  volume=61,
  number=1,
  pages={193--202},
  year=2015,
  publisher={Springer US},
  doi = {10.1007/s10898-014-0150-x},
  eprint={1501.07298},
  eprinttype = {arxiv}
}

@article{malitsky2015projected,
  title={Projected reflected gradient methods for monotone variational inequalities},
  author={Malitsky, Yura},
  journal={SIAM Journal on Optimization},
  volume=25,
  number=1,
  pages={502--520},
  year=2015,
  publisher={SIAM},
  doi="10.1137/14097238X",
  eprint={1502.04968},
  eprinttype = {arxiv},
  abstract = {SIAM Student Paper Award, 2015}
}



@article{malitsky2014extragradient,
  title={An extragradient algorithm for monotone variational inequalities},
  author={Malitsky, Yura V and Semenov, VV},
  journal={Cybernetics and Systems Analysis},
  volume=50,
  number=2,
  pages={271--277},
  year=2014,
  publisher={Springer US},
  doi={10.1007/s10559-014-9614-8}
}
